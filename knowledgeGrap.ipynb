{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_3716\\339290948.py:27: DeprecationWarning: Call to deprecated method findAll. (Replaced by find_all) -- Deprecated since version 4.0.0.\n",
      "  review_elements = soup.findAll(\"article\", attrs={'class':'css-ccpe8t'})\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_3716\\339290948.py:32: DeprecationWarning: Call to deprecated method findAll. (Replaced by find_all) -- Deprecated since version 4.0.0.\n",
      "  product_container = review.findAll(\"a\",attrs={\"class\":\"styProduct\"})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there is error\n",
      "there is error\n",
      "there is error\n",
      "there is error\n",
      "there is error\n",
      "there is error\n",
      "there is error\n",
      "there is error\n",
      "there is error\n",
      "there is error\n",
      "there is error\n",
      "there is error\n",
      "there is error\n",
      "there is error\n",
      "there is error\n",
      "there is error\n",
      "there is error\n",
      "there is error\n",
      "there is error\n",
      "there is error\n",
      "there is error\n",
      "there is error\n",
      "there is error\n",
      "there is error\n",
      "No more pages.\n",
      "Scraping selesai! Data disimpan dalam tokopedia_reviews.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "service = Service(ChromeDriverManager().install())\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "# Ganti dengan URL halaman review toko di Tokopedia\n",
    "url = \"https://www.tokopedia.com/dkmall/review\"\n",
    "\n",
    "driver.get(url)\n",
    "\n",
    "reviews = []\n",
    "\n",
    "while True:\n",
    "    # Ambil elemen review\n",
    "    time.sleep(3)  # Tunggu halaman masuk\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    try:\n",
    "        review_elements = soup.findAll(\"article\", attrs={'class':'css-ccpe8t'})\n",
    "\n",
    "        for review in review_elements:\n",
    "            username = review.find(\"span\", attrs={\"class\":\"name\"}).text\n",
    "            comment = review.find(\"span\", attrs={\"data-testid\":\"lblItemUlasan\"}).text\n",
    "            product_container = review.findAll(\"a\",attrs={\"class\":\"styProduct\"})\n",
    "\n",
    "            for element in product_container:\n",
    "                product = review.find(\"p\", attrs={\"data-unify\":\"Typography\"}).text\n",
    "                \n",
    "                reviews.append({\n",
    "                    \"username\": username,\n",
    "                    \"review\": comment,\n",
    "                    \"product\": product\n",
    "                })\n",
    "    except:\n",
    "        print(\"there is error\")\n",
    "        \n",
    "    # Cek apakah ada tombol \"Next\" untuk lanjut ke halaman berikutnya\n",
    "    try:\n",
    "        next_button = driver.find_element(By.CSS_SELECTOR, 'button[aria-label=\"Laman berikutnya\"]')\n",
    "        next_button.click()\n",
    "        time.sleep(2)\n",
    "    except:\n",
    "        print(\"No more pages.\")\n",
    "        break  # Keluar jika tidak ada tombol \"Next\"\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "# Simpan ke CSV\n",
    "df = pd.DataFrame(reviews)\n",
    "df.to_csv(\"tokopedia_review.csv\", index=False)\n",
    "print(\"Scraping selesai! Data disimpan dalam tokopedia_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data dari csv: \n",
      "  username                                             review  \\\n",
      "0    ANDRI  mendarat dengan aman, packing aman, engga boco...   \n",
      "1    K***s  thank you, hotto nya asli, pengiriman cepat, h...   \n",
      "2   Awalia                                             mantap   \n",
      "3    gugun                                               good   \n",
      "4  Marissa                                     sesuai pesanan   \n",
      "\n",
      "                                             product  \n",
      "0  Autumn 7% Glycolic Acid Toner Solution Exfolia...  \n",
      "1  Hotto Purto Multigrain Superfood Purple Potato...  \n",
      "2  Azarine Calm My Acne Sunscreen Moisturiser SPF...  \n",
      "3  Ms Glow Men Energizer Facial Wash / Face Wash ...  \n",
      "4   Golden Viera Soap Original Asli Paket Hemat 3pcs  \n",
      "  username                                             review  \\\n",
      "0    ANDRI  mendarat dengan aman, packing aman, engga boco...   \n",
      "1    K***s  thank you, hotto nya asli, pengiriman cepat, h...   \n",
      "2   Awalia                                             mantap   \n",
      "3    gugun                                               good   \n",
      "4  Marissa                                     sesuai pesanan   \n",
      "\n",
      "                                             product  \\\n",
      "0  Autumn 7% Glycolic Acid Toner Solution Exfolia...   \n",
      "1  Hotto Purto Multigrain Superfood Purple Potato...   \n",
      "2  Azarine Calm My Acne Sunscreen Moisturiser SPF...   \n",
      "3  Ms Glow Men Energizer Facial Wash / Face Wash ...   \n",
      "4   Golden Viera Soap Original Asli Paket Hemat 3pcs   \n",
      "\n",
      "                                        clean_review  \n",
      "0    darat aman packing aman engga bocor kirim cepat  \n",
      "1  thank you hotto nya asli kirim cepat harga sah...  \n",
      "2                                             mantap  \n",
      "3                                               good  \n",
      "4                                       sesuai pesan  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "import re\n",
    "\n",
    "# Load data hasil scraping\n",
    "df = pd.read_csv(\"tokopedia_review.csv\")\n",
    "\n",
    "# Tampilkan contoh data\n",
    "print(\"data dari csv: \")\n",
    "print(df.head())\n",
    "\n",
    "# Inisialisasi stopword remover & stemmer\n",
    "stopword_factory = StopWordRemoverFactory()\n",
    "stopword_remover = stopword_factory.create_stop_word_remover()\n",
    "stemmer_factory = StemmerFactory()\n",
    "stemmer = stemmer_factory.create_stemmer()\n",
    "\n",
    "# Fungsi preprocessing\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # Lowercase\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)  # Hapus karakter spesial\n",
    "    text = stopword_remover.remove(text)  # Hapus stopword\n",
    "    text = stemmer.stem(text)  # Stemming\n",
    "    return text\n",
    "\n",
    "# Terapkan ke data\n",
    "df[\"clean_review\"] = df[\"review\"].astype(str).apply(clean_text)\n",
    "\n",
    "slang_dict = {\n",
    "    \"yg\": \"yang\",\n",
    "    \"bgt\": \"banget\",\n",
    "    \"tdk\": \"tidak\",\n",
    "    \"gk\": \"gak\",\n",
    "    \"trs\": \"terus\",\n",
    "    \"bnr2\": \"benar-benar\",\n",
    "    \"kayu2\": \"kayu-kayu\",\n",
    "    \"sukaaa\": \"sukaaa\",\n",
    "    \"jd\" : \"jadi\",\n",
    "    \"byk2\" : \"banyak\",\n",
    "    \"mantaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaap\": \"mantap\",\n",
    "    \"bsnahabbaabananananananananananananananannaannaananan\":\"\"\n",
    "}\n",
    "\n",
    "def normalize_slang(text):\n",
    "    words = text.split()\n",
    "    words = [slang_dict[word] if word in slang_dict else word for word in words]\n",
    "    return \" \".join(words)\n",
    "\n",
    "df[\"clean_review\"] = df[\"clean_review\"].apply(normalize_slang)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  username                                             review  \\\n",
      "0    ANDRI  mendarat dengan aman, packing aman, engga boco...   \n",
      "1    K***s  thank you, hotto nya asli, pengiriman cepat, h...   \n",
      "2   Awalia                                             mantap   \n",
      "3    gugun                                               good   \n",
      "4  Marissa                                     sesuai pesanan   \n",
      "\n",
      "                                             product  \\\n",
      "0  Autumn 7% Glycolic Acid Toner Solution Exfolia...   \n",
      "1  Hotto Purto Multigrain Superfood Purple Potato...   \n",
      "2  Azarine Calm My Acne Sunscreen Moisturiser SPF...   \n",
      "3  Ms Glow Men Energizer Facial Wash / Face Wash ...   \n",
      "4   Golden Viera Soap Original Asli Paket Hemat 3pcs   \n",
      "\n",
      "                                        clean_review  \\\n",
      "0    darat aman packing aman engga bocor kirim cepat   \n",
      "1  thank you hotto nya asli kirim cepat harga sah...   \n",
      "2                                             mantap   \n",
      "3                                               good   \n",
      "4                                       sesuai pesan   \n",
      "\n",
      "                                        entities  \n",
      "0  [(aman, PER), (engga bocor kirim cepat, PER)]  \n",
      "1         [(thank you, MISC), (asli kirim, PER)]  \n",
      "2                                             []  \n",
      "3                                             []  \n",
      "4                         [(sesuai pesan, MISC)]  \n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"xx_ent_wiki_sm\")  # Model NER multibahasa\n",
    "\n",
    "def extract_entities(text):\n",
    "    doc = nlp(text)\n",
    "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "    return entities\n",
    "\n",
    "df[\"entities\"] = df[\"clean_review\"].astype(str).apply(extract_entities)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n",
      "knowledge_graph.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800px\"\n",
       "            src=\"knowledge_graph.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x2a391a5fc50>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "\n",
    "G = nx.Graph()\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    user = row[\"username\"]\n",
    "    review = row[\"clean_review\"]\n",
    "    entities = row[\"entities\"]\n",
    "\n",
    "    # Tambahkan node user\n",
    "    G.add_node(user, type=\"User\")\n",
    "\n",
    "    # Tambahkan node entitas (Produk/Sentimen)\n",
    "    for ent_text, ent_label in entities:\n",
    "        G.add_node(ent_text, type=ent_label)\n",
    "        G.add_edge(user, ent_text, relation=\"review\")  # Hubungkan user dengan entitas\n",
    "\n",
    "# Visualisasi Knowledge Graph\n",
    "net = Network(notebook=True, height=\"800px\", width=\"100%\", bgcolor=\"#222222\", font_color=\"white\")\n",
    "net.from_nx(G)\n",
    "\n",
    "# Tambahkan fitur interaktif\n",
    "net.toggle_physics(True)  # Aktifkan fisika agar node tidak tumpang tindih\n",
    "net.force_atlas_2based(gravity=-50, central_gravity=0.01)  # Sesuaikan gaya tarik antar node\n",
    "\n",
    "# Simpan ke file HTML dan tampilkan\n",
    "net.show(\"knowledge_graph.html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
